./docker-compose.yaml:version: "3.8"
./docker-compose.yaml:
./docker-compose.yaml:services:
./docker-compose.yaml:  flask_model_server:
./docker-compose.yaml:    build:
./docker-compose.yaml:      context: ./flask_model_server
./docker-compose.yaml:      dockerfile: Dockerfile
./docker-compose.yaml:    ports:
./docker-compose.yaml:      - "5000:5000"
./docker-compose.yaml:    volumes:
./docker-compose.yaml:      - training_artifacts:/storage/training_artifacts
./docker-compose.yaml:      - mlflow_logs:/storage/mlflow_logs
./docker-compose.yaml:      - parameters:/storage/parameters
./docker-compose.yaml:
./docker-compose.yaml:  mlflow_server:
./docker-compose.yaml:    build:
./docker-compose.yaml:      context: ./mlflow_server
./docker-compose.yaml:      dockerfile: Dockerfile
./docker-compose.yaml:    ports:
./docker-compose.yaml:      - "5001:5001"
./docker-compose.yaml:    volumes:
./docker-compose.yaml:      - training_artifacts:/storage/training_artifacts
./docker-compose.yaml:      - mlflow_logs:/storage/mlflow_logs
./docker-compose.yaml:
./docker-compose.yaml:volumes:
./docker-compose.yaml:  mlflow_logs: 
./docker-compose.yaml:  training_artifacts: 
./docker-compose.yaml:  parameters:
./content.sh:#!/bin/bash
./content.sh:
./content.sh:# Se um diretório for passado como argumento, usa-o; caso contrário, usa o diretório atual.
./content.sh:TARGET_DIR="${1:-.}"
./content.sh:
./content.sh:# Usa o comando find para localizar os arquivos, ignorando diretórios chamados ".venv".
./content.sh:# A opção -prune faz com que o find não desça na árvore dos diretórios correspondentes.
./content.sh:find "$TARGET_DIR" -type d -name ".venv" -prune -o -type f -print | while read -r file; do
./content.sh:    echo "Arquivo: $file"
./content.sh:    echo "Conteúdo:"
./content.sh:    cat "$file"
./content.sh:    echo -e "\n----------------------\n"
./content.sh:done
./flask_model_server/models/lstm_model.py:import torch
./flask_model_server/models/lstm_model.py:import torch.nn as nn
./flask_model_server/models/lstm_model.py:from config import DEVICE
./flask_model_server/models/lstm_model.py:
./flask_model_server/models/lstm_model.py:class LSTMModel(nn.Module):
./flask_model_server/models/lstm_model.py:    def __init__(self, input_size=1, hidden_size=100, num_layers=1, output_size=1):
./flask_model_server/models/lstm_model.py:        super().__init__()
./flask_model_server/models/lstm_model.py:        self.hidden_size = hidden_size
./flask_model_server/models/lstm_model.py:        self.num_layers = num_layers
./flask_model_server/models/lstm_model.py:        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
./flask_model_server/models/lstm_model.py:        self.fc1 = nn.Linear(hidden_size, output_size)
./flask_model_server/models/lstm_model.py:        self.sigmoid = nn.Sigmoid()
./flask_model_server/models/lstm_model.py:        self.lstm2 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
./flask_model_server/models/lstm_model.py:        self.fc2 = nn.Linear(hidden_size, output_size)
./flask_model_server/models/lstm_model.py:
./flask_model_server/models/lstm_model.py:    def forward(self, x):
./flask_model_server/models/lstm_model.py:        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)
./flask_model_server/models/lstm_model.py:        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(DEVICE)
./flask_model_server/models/lstm_model.py:        out, _ = self.lstm1(x, (h0, c0))
./flask_model_server/models/lstm_model.py:        out = self.fc1(out[:, -1, :])
./flask_model_server/models/lstm_model.py:        out = self.sigmoid(out)
./flask_model_server/models/lstm_model.py:        out2, _ = self.lstm2(x, (h0, c0))
./flask_model_server/models/lstm_model.py:        out2 = self.fc2(out2[:, -1, :])
./flask_model_server/models/lstm_model.py:        return out
./flask_model_server/training/predict.py:import os
./flask_model_server/training/predict.py:import pickle
./flask_model_server/training/predict.py:import numpy as np
./flask_model_server/training/predict.py:import torch
./flask_model_server/training/predict.py:import yfinance as yf
./flask_model_server/training/predict.py:from datetime import datetime, timedelta
./flask_model_server/training/predict.py:from models.lstm_model import LSTMModel
./flask_model_server/training/predict.py:from utils.config_loader import load_parameters
./flask_model_server/training/predict.py:from config import MODEL_LOCAL_PATH, SCALER_LOCAL_PATH, LAST_UPDATE_FILE, DEVICE
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:def get_last_update():
./flask_model_server/training/predict.py:    if os.path.exists(LAST_UPDATE_FILE):
./flask_model_server/training/predict.py:        try:
./flask_model_server/training/predict.py:            with open(LAST_UPDATE_FILE, "r") as f:
./flask_model_server/training/predict.py:                date_str = f.read().strip()
./flask_model_server/training/predict.py:            return datetime.strptime(date_str, "%Y-%m-%d").date()
./flask_model_server/training/predict.py:        except Exception:
./flask_model_server/training/predict.py:            pass
./flask_model_server/training/predict.py:    params = load_parameters()
./flask_model_server/training/predict.py:    date_zero_str = params.get("DATE_ZERO", "2010-01-01")
./flask_model_server/training/predict.py:    return datetime.strptime(date_zero_str, "%Y-%m-%d").date()
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:def run_prediction(date_str):
./flask_model_server/training/predict.py:    params = load_parameters()
./flask_model_server/training/predict.py:    ticker = params.get("TICKER", "AAPL")
./flask_model_server/training/predict.py:    sequence_length = int(params.get("SEQUENCE_LENGTH", 5))
./flask_model_server/training/predict.py:    hidden_size = int(params.get("HIDDEN_SIZE", 100))
./flask_model_server/training/predict.py:    num_layers = int(params.get("NUM_LAYERS", 3))
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    try:
./flask_model_server/training/predict.py:        target_date = datetime.strptime(date_str, "%Y-%m-%d").date()
./flask_model_server/training/predict.py:    except ValueError:
./flask_model_server/training/predict.py:        return {"error": "Formato de data inválido. Use YYYY-MM-DD."}
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    if not os.path.exists(MODEL_LOCAL_PATH) or not os.path.exists(SCALER_LOCAL_PATH):
./flask_model_server/training/predict.py:        return {"error": "Modelo ou Scaler não encontrados. Execute /train primeiro."}
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    model = LSTMModel(input_size=1, hidden_size=hidden_size,
./flask_model_server/training/predict.py:                      num_layers=num_layers, output_size=1).to(DEVICE)
./flask_model_server/training/predict.py:    model.load_state_dict(torch.load(MODEL_LOCAL_PATH))
./flask_model_server/training/predict.py:    model.eval()
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    with open(SCALER_LOCAL_PATH, "rb") as f:
./flask_model_server/training/predict.py:        scaler = pickle.load(f)
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    last_date = get_last_update()
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:    if target_date > last_date:
./flask_model_server/training/predict.py:        start_date_seq = (last_date - timedelta(days=sequence_length * 3)).strftime("%Y-%m-%d")
./flask_model_server/training/predict.py:        end_date_seq = (last_date + timedelta(days=1)).strftime("%Y-%m-%d")
./flask_model_server/training/predict.py:        df_seq = yf.download(ticker, start=start_date_seq, end=end_date_seq, progress=False)
./flask_model_server/training/predict.py:        if df_seq.empty or len(df_seq) < sequence_length:
./flask_model_server/training/predict.py:            return {"error": "Histórico insuficiente para formar uma sequência de entrada."}
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:        last_sequence = df_seq["Close"].values[-sequence_length:]
./flask_model_server/training/predict.py:        last_sequence = last_sequence.reshape(-1, 1)
./flask_model_server/training/predict.py:        last_sequence_scaled = scaler.transform(last_sequence)
./flask_model_server/training/predict.py:        current_sequence = torch.tensor(last_sequence_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
./flask_model_server/training/predict.py:
./flask_model_server/training/predict.py:        num_days = (target_date - last_date).days
./flask_model_server/training/predict.py:        predictions_scaled = []
./flask_model_server/training/predict.py:        for _ in range(num_days):
./flask_model_server/training/predict.py:            with torch.no_grad():
./flask_model_server/training/predict.py:                pred = model(current_sequence)
./flask_model_server/training/predict.py:            predictions_scaled.append(pred.item())
./flask_model_server/training/predict.py:            pred_tensor = pred.view(1, 1, 1)
./flask_model_server/training/predict.py:            current_sequence = torch.cat((current_sequence[:, 1:, :], pred_tensor), dim=1)
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        final_pred_scaled = np.array([[predictions_scaled[-1]]])
./flask_model_server/training/predict.py:        predicted_value = scaler.inverse_transform(final_pred_scaled)[0, 0]
./flask_model_server/training/predict.py:        return {
./flask_model_server/training/predict.py:            "date": date_str,
./flask_model_server/training/predict.py:            "predicted_close_price": predicted_value,
./flask_model_server/training/predict.py:            "note": "Prediction for a future date (untrained)"
./flask_model_server/training/predict.py:        }
./flask_model_server/training/predict.py:    else:
./flask_model_server/training/predict.py:        start_date_seq = (target_date - timedelta(days=sequence_length * 3)).strftime("%Y-%m-%d")
./flask_model_server/training/predict.py:        end_date_seq = target_date.strftime("%Y-%m-%d")
./flask_model_server/training/predict.py:        df_seq = yf.download(ticker, start=start_date_seq, end=end_date_seq, progress=False)
./flask_model_server/training/predict.py:        if df_seq.empty or len(df_seq) < sequence_length:
./flask_model_server/training/predict.py:            return {"error": "Histórico insuficiente para formar uma sequência de entrada para a data informada."}
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        df_seq = df_seq[df_seq.index < pd.Timestamp(target_date)]
./flask_model_server/training/predict.py:        if len(df_seq) < sequence_length:
./flask_model_server/training/predict.py:            return {"error": "Histórico insuficiente para formar uma sequência de entrada para a data fornecida."}
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        last_sequence = df_seq["Close"].values[-sequence_length:]
./flask_model_server/training/predict.py:        last_sequence = last_sequence.reshape(-1, 1)
./flask_model_server/training/predict.py:        last_sequence_scaled = scaler.transform(last_sequence)
./flask_model_server/training/predict.py:        current_sequence = torch.tensor(last_sequence_scaled, dtype=torch.float32).unsqueeze(0).to(DEVICE)
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        with torch.no_grad():
./flask_model_server/training/predict.py:            pred = model(current_sequence)
./flask_model_server/training/predict.py:        predicted_scaled = pred.item()
./flask_model_server/training/predict.py:        predicted_value = scaler.inverse_transform(np.array([[predicted_scaled]]))[0, 0]
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        df_actual = yf.download(
./flask_model_server/training/predict.py:            ticker,
./flask_model_server/training/predict.py:            start=target_date.strftime("%Y-%m-%d"),
./flask_model_server/training/predict.py:            end=(target_date + timedelta(days=1)).strftime("%Y-%m-%d"),
./flask_model_server/training/predict.py:            progress=False
./flask_model_server/training/predict.py:        )
./flask_model_server/training/predict.py:        actual_value = None
./flask_model_server/training/predict.py:        if not df_actual.empty:
./flask_model_server/training/predict.py:            actual_value = float(df_actual["Close"].iloc[0])
./flask_model_server/training/predict.py:        
./flask_model_server/training/predict.py:        return {
./flask_model_server/training/predict.py:            "date": date_str,
./flask_model_server/training/predict.py:            "predicted_close_price": predicted_value,
./flask_model_server/training/predict.py:            "actual_close_price": actual_value,
./flask_model_server/training/predict.py:            "note": "Prediction for a trained date (for accuracy comparison)"
./flask_model_server/training/predict.py:        }
./flask_model_server/training/train.py:import os
./flask_model_server/training/train.py:import pickle
./flask_model_server/training/train.py:import mlflow
./flask_model_server/training/train.py:import numpy as np
./flask_model_server/training/train.py:import torch
./flask_model_server/training/train.py:import torch.optim as optim
./flask_model_server/training/train.py:from datetime import datetime
./flask_model_server/training/train.py:from models.lstm_model import LSTMModel
./flask_model_server/training/train.py:from utils.config_loader import load_parameters
./flask_model_server/training/train.py:from utils.data_utils import download_data_from_yfinance, preprocess_data
./flask_model_server/training/train.py:from config import LOGS_DIR, MODEL_LOCAL_PATH, SCALER_LOCAL_PATH, LAST_UPDATE_FILE, STEP_COUNT_FILE, DEVICE
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:mlflow.set_tracking_uri("sqlite:///" + os.path.join(LOGS_DIR, "mlflow.db"))
./flask_model_server/training/train.py:mlflow.set_experiment("stock_prediction")
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:def get_last_update():
./flask_model_server/training/train.py:    if os.path.exists(LAST_UPDATE_FILE):
./flask_model_server/training/train.py:        try:
./flask_model_server/training/train.py:            with open(LAST_UPDATE_FILE, "r") as f:
./flask_model_server/training/train.py:                date_str = f.read().strip()
./flask_model_server/training/train.py:            return datetime.strptime(date_str, "%Y-%m-%d").date()
./flask_model_server/training/train.py:        except Exception:
./flask_model_server/training/train.py:            pass
./flask_model_server/training/train.py:    # Se não houver last_update, usa DATE_ZERO de params.txt
./flask_model_server/training/train.py:    params = load_parameters()
./flask_model_server/training/train.py:    date_zero_str = params.get("DATE_ZERO", "2010-01-01")
./flask_model_server/training/train.py:    return datetime.strptime(date_zero_str, "%Y-%m-%d").date()
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:def set_last_update(date_obj):
./flask_model_server/training/train.py:    with open(LAST_UPDATE_FILE, "w") as f:
./flask_model_server/training/train.py:        f.write(date_obj.strftime("%Y-%m-%d"))
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:def get_step_count():
./flask_model_server/training/train.py:    if os.path.exists(STEP_COUNT_FILE):
./flask_model_server/training/train.py:        try:
./flask_model_server/training/train.py:            with open(STEP_COUNT_FILE, "r") as f:
./flask_model_server/training/train.py:                return int(f.read().strip())
./flask_model_server/training/train.py:        except Exception:
./flask_model_server/training/train.py:            pass
./flask_model_server/training/train.py:    return 0
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:def set_step_count(step):
./flask_model_server/training/train.py:    with open(STEP_COUNT_FILE, "w") as f:
./flask_model_server/training/train.py:        f.write(str(step))
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:def run_training(reset=False):
./flask_model_server/training/train.py:    params = load_parameters()
./flask_model_server/training/train.py:    ticker = params.get("TICKER", "AAPL")
./flask_model_server/training/train.py:    sequence_length = int(params.get("SEQUENCE_LENGTH", 5))
./flask_model_server/training/train.py:    epochs = int(params.get("EPOCHS", 100))
./flask_model_server/training/train.py:    learning_rate = float(params.get("LEARNING_RATE", 0.0005))
./flask_model_server/training/train.py:    hidden_size = int(params.get("HIDDEN_SIZE", 100))
./flask_model_server/training/train.py:    num_layers = int(params.get("NUM_LAYERS", 3))
./flask_model_server/training/train.py:    date_zero_str = params.get("DATE_ZERO", "2010-01-01")
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:    step = get_step_count()
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:    if reset:
./flask_model_server/training/train.py:        try:
./flask_model_server/training/train.py:            date_zero = datetime.strptime(date_zero_str, "%Y-%m-%d").date()
./flask_model_server/training/train.py:        except Exception:
./flask_model_server/training/train.py:            date_zero = datetime(2010, 1, 1).date()
./flask_model_server/training/train.py:        set_last_update(date_zero)
./flask_model_server/training/train.py:        print(f"Reset solicitado: last_update definido para {date_zero}")
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:    with mlflow.start_run():
./flask_model_server/training/train.py:        # Loga os parâmetros do treinamento no MLflow
./flask_model_server/training/train.py:        mlflow.log_param("epochs", epochs)
./flask_model_server/training/train.py:        mlflow.log_param("sequence_length", sequence_length)
./flask_model_server/training/train.py:        mlflow.log_param("learning_rate", learning_rate)
./flask_model_server/training/train.py:        mlflow.log_param("ticker", ticker)
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:        last_update = get_last_update()
./flask_model_server/training/train.py:        df = download_data_from_yfinance(last_update, ticker)
./flask_model_server/training/train.py:        if df is None:
./flask_model_server/training/train.py:            return {"error": "Erro ao baixar dados do Yahoo Finance"}
./flask_model_server/training/train.py:        
./flask_model_server/training/train.py:        X_np, y_np, scaler = preprocess_data(df, sequence_length, DEVICE)
./flask_model_server/training/train.py:        X = torch.tensor(X_np).to(DEVICE)
./flask_model_server/training/train.py:        y = torch.tensor(y_np).to(DEVICE)
./flask_model_server/training/train.py:        
./flask_model_server/training/train.py:        model = LSTMModel(input_size=1, hidden_size=hidden_size,
./flask_model_server/training/train.py:                        num_layers=num_layers, output_size=1).to(DEVICE)
./flask_model_server/training/train.py:        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
./flask_model_server/training/train.py:        criterion = torch.nn.MSELoss()
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:        if os.path.exists(MODEL_LOCAL_PATH) and os.path.getsize(MODEL_LOCAL_PATH) > 0:
./flask_model_server/training/train.py:            model.load_state_dict(torch.load(MODEL_LOCAL_PATH))
./flask_model_server/training/train.py:            print("Modelo carregado para re-treinamento.")
./flask_model_server/training/train.py:        else:
./flask_model_server/training/train.py:            print("Treinando modelo do zero.")
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:        for epoch in range(epochs):
./flask_model_server/training/train.py:            model.train()
./flask_model_server/training/train.py:            optimizer.zero_grad()
./flask_model_server/training/train.py:            y_pred = model(X)
./flask_model_server/training/train.py:            loss = criterion(y_pred, y)
./flask_model_server/training/train.py:            loss.backward()
./flask_model_server/training/train.py:            optimizer.step()
./flask_model_server/training/train.py:            print(f"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.6f}")
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:        model.eval()
./flask_model_server/training/train.py:        with torch.no_grad():
./flask_model_server/training/train.py:            train_preds = model(X)
./flask_model_server/training/train.py:        train_preds_np = train_preds.cpu().numpy()
./flask_model_server/training/train.py:        y_np = y.cpu().numpy()
./flask_model_server/training/train.py:        mae = float(np.mean(np.abs(train_preds_np - y_np)))
./flask_model_server/training/train.py:        rmse = float(np.sqrt(np.mean((train_preds_np - y_np) ** 2)))
./flask_model_server/training/train.py:        epsilon = 1e-8  # Para evitar divisão por zero
./flask_model_server/training/train.py:        mape = float(np.mean(np.abs((train_preds_np - y_np) / (y_np + epsilon))) * 100)
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:        mlflow.log_metric("loss", float(loss.item()), step=step)
./flask_model_server/training/train.py:        mlflow.log_metric("mae", mae, step=step)
./flask_model_server/training/train.py:        mlflow.log_metric("rmse", rmse, step=step)
./flask_model_server/training/train.py:        mlflow.log_metric("mape", mape, step=step)
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:    # Salva os artefatos (modelo e scaler)
./flask_model_server/training/train.py:    torch.save(model.state_dict(), MODEL_LOCAL_PATH)
./flask_model_server/training/train.py:    with open(SCALER_LOCAL_PATH, "wb") as f:
./flask_model_server/training/train.py:        pickle.dump(scaler, f)
./flask_model_server/training/train.py:
./flask_model_server/training/train.py:    set_step_count(step + 1)
./flask_model_server/training/train.py:    
./flask_model_server/training/train.py:    return {
./flask_model_server/training/train.py:        "status": "Treinamento concluído com sucesso!",
./flask_model_server/training/train.py:        "loss": float(loss.item()),
./flask_model_server/training/train.py:        "mae": mae,
./flask_model_server/training/train.py:        "rmse": rmse,
./flask_model_server/training/train.py:        "mape": mape
./flask_model_server/training/train.py:    }
./flask_model_server/app.py:# app.py
./flask_model_server/app.py:import os
./flask_model_server/app.py:from flask import Flask, request, jsonify
./flask_model_server/app.py:from training.train import run_training
./flask_model_server/app.py:from training.predict import run_prediction
./flask_model_server/app.py:from config import ARTIFACTS_DIR, LOGS_DIR
./flask_model_server/app.py:
./flask_model_server/app.py:app = Flask(__name__)
./flask_model_server/app.py:
./flask_model_server/app.py:@app.route("/train", methods=["GET"])
./flask_model_server/app.py:def train():
./flask_model_server/app.py:    reset_flag = request.args.get("reset", "false").lower() in ("true", "1", "yes")
./flask_model_server/app.py:    result = run_training(reset=reset_flag)
./flask_model_server/app.py:    return jsonify(result), 200
./flask_model_server/app.py:
./flask_model_server/app.py:@app.route("/predict", methods=["GET"])
./flask_model_server/app.py:def predict():
./flask_model_server/app.py:    date_str = request.args.get("date")
./flask_model_server/app.py:    if not date_str:
./flask_model_server/app.py:        return jsonify({"error": "A data deve ser fornecida no formato YYYY-MM-DD"}), 400
./flask_model_server/app.py:    result = run_prediction(date_str)
./flask_model_server/app.py:    return jsonify(result), 200
./flask_model_server/app.py:
./flask_model_server/app.py:@app.route("/artifacts", methods=["GET"])
./flask_model_server/app.py:def list_artifacts():
./flask_model_server/app.py:    artifacts = []
./flask_model_server/app.py:    for root, dirs, files in os.walk(ARTIFACTS_DIR):
./flask_model_server/app.py:        for file in files:
./flask_model_server/app.py:            rel_dir = os.path.relpath(root, ARTIFACTS_DIR)
./flask_model_server/app.py:            rel_file = os.path.join(rel_dir, file) if rel_dir != '.' else file
./flask_model_server/app.py:            artifacts.append(rel_file)
./flask_model_server/app.py:    return jsonify({"artifacts": artifacts})
./flask_model_server/app.py:
./flask_model_server/app.py:if __name__ == "__main__":
./flask_model_server/app.py:    app.run(host="0.0.0.0", port=5000)
./flask_model_server/requirements.txt:Flask
./flask_model_server/requirements.txt:torch
./flask_model_server/requirements.txt:numpy
./flask_model_server/requirements.txt:pandas
./flask_model_server/requirements.txt:yfinance
./flask_model_server/requirements.txt:scikit-learn
./flask_model_server/requirements.txt:mlflow==2.17.1
./flask_model_server/config.py:# config.py
./flask_model_server/config.py:import os
./flask_model_server/config.py:import torch
./flask_model_server/config.py:import sys
./flask_model_server/config.py:import shutil
./flask_model_server/config.py:
./flask_model_server/config.py:BASE_DIR = os.path.dirname(os.path.abspath(__file__))
./flask_model_server/config.py:LOCAL = sys.argv[-1] == 'local' # sessão local ou remota (container)
./flask_model_server/config.py:
./flask_model_server/config.py:print(f"Running locally: {LOCAL}")
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:## ARTIFACTS
./flask_model_server/config.py:
./flask_model_server/config.py:# Diretório para armazenar os artefatos do treinamento (modelo, scaler, last_update, etc.)
./flask_model_server/config.py:if LOCAL:
./flask_model_server/config.py:    ARTIFACTS_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../local_storage/training_artifacts"))
./flask_model_server/config.py:else:
./flask_model_server/config.py:    ARTIFACTS_DIR = os.path.abspath(os.path.join("/storage/", "training_artifacts"))
./flask_model_server/config.py:
./flask_model_server/config.py:if not os.path.exists(ARTIFACTS_DIR):
./flask_model_server/config.py:    os.makedirs(ARTIFACTS_DIR)
./flask_model_server/config.py:
./flask_model_server/config.py:print(f"ARTIFACTS_DIR: {ARTIFACTS_DIR}")
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:## MLFLOW LOGS
./flask_model_server/config.py:
./flask_model_server/config.py:# Diretório para armazenar os logs do MLflow
./flask_model_server/config.py:if LOCAL:
./flask_model_server/config.py:    LOGS_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../local_storage/mlflow_logs"))
./flask_model_server/config.py:else:
./flask_model_server/config.py:    LOGS_DIR = os.path.abspath(os.path.join("/storage/", "mlflow_logs"))
./flask_model_server/config.py:
./flask_model_server/config.py:if not os.path.exists(LOGS_DIR):
./flask_model_server/config.py:    os.makedirs(LOGS_DIR)
./flask_model_server/config.py:
./flask_model_server/config.py:print(f"LOGS_DIR: {LOGS_DIR}")
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:## PARAMS
./flask_model_server/config.py:
./flask_model_server/config.py:# Diretório para armazenar os parâmetros
./flask_model_server/config.py:if LOCAL:
./flask_model_server/config.py:    PARAMS_DIR = os.path.abspath(os.path.join(BASE_DIR, "../../local_storage/params"))
./flask_model_server/config.py:else:
./flask_model_server/config.py:    PARAMS_DIR = os.path.abspath(os.path.join("/storage/", "params"))
./flask_model_server/config.py:
./flask_model_server/config.py:if not os.path.exists(PARAMS_DIR):
./flask_model_server/config.py:    os.makedirs(PARAMS_DIR)
./flask_model_server/config.py:
./flask_model_server/config.py:if not os.path.exists(os.path.join(PARAMS_DIR, "params.txt")):
./flask_model_server/config.py:    shutil.copyfile(os.path.join(BASE_DIR, "default_params.txt"), os.path.join(PARAMS_DIR, "params.txt"))
./flask_model_server/config.py:    print(f"Default params.txt copied to {PARAMS_DIR}")
./flask_model_server/config.py:
./flask_model_server/config.py:print(f"PARAMS_DIR: {LOGS_DIR}")
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:
./flask_model_server/config.py:# Caminhos para arquivos gerados (dentro do diretório de artefatos)
./flask_model_server/config.py:MODEL_LOCAL_PATH = os.path.join(ARTIFACTS_DIR, "model_lstm.pt")
./flask_model_server/config.py:SCALER_LOCAL_PATH = os.path.join(ARTIFACTS_DIR, "scaler.pkl")
./flask_model_server/config.py:LAST_UPDATE_FILE = os.path.join(ARTIFACTS_DIR, "last_update.txt")
./flask_model_server/config.py:STEP_COUNT_FILE = os.path.join(ARTIFACTS_DIR, "step_count.txt")
./flask_model_server/config.py:
./flask_model_server/config.py:# Configuração do dispositivo para PyTorch
./flask_model_server/config.py:DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
./flask_model_server/default_params.txt:# Parâmetros para treinamento e predição
./flask_model_server/default_params.txt:TICKER=AAPL
./flask_model_server/default_params.txt:SEQUENCE_LENGTH=5
./flask_model_server/default_params.txt:EPOCHS=100
./flask_model_server/default_params.txt:BATCH_SIZE=32
./flask_model_server/default_params.txt:LEARNING_RATE=0.0005
./flask_model_server/default_params.txt:HIDDEN_SIZE=100
./flask_model_server/default_params.txt:NUM_LAYERS=3
./flask_model_server/default_params.txt:DATE_ZERO=2010-01-01
./flask_model_server/local_run.sh:#!/usr/bin/env bash
./flask_model_server/local_run.sh:source .venv/bin/activate
./flask_model_server/local_run.sh:python3 app.py local
./flask_model_server/local_run.sh:deactivate
./flask_model_server/local_setup.sh:#!/usr/bin/env bash
./flask_model_server/local_setup.sh:python3 -m venv .venv
./flask_model_server/local_setup.sh:source .venv/bin/activate
./flask_model_server/local_setup.sh:pip3 install -r requirements.txt
./flask_model_server/local_setup.sh:deactivate
./flask_model_server/utils/config_loader.py:import os
./flask_model_server/utils/config_loader.py:from config import PARAMS_DIR
./flask_model_server/utils/config_loader.py:
./flask_model_server/utils/config_loader.py:def load_parameters():
./flask_model_server/utils/config_loader.py:    params = {}
./flask_model_server/utils/config_loader.py:    file_path = f"{PARAMS_DIR}/params.txt"
./flask_model_server/utils/config_loader.py:    if os.path.exists(file_path):
./flask_model_server/utils/config_loader.py:        with open(file_path, "r") as f:
./flask_model_server/utils/config_loader.py:            for line in f:
./flask_model_server/utils/config_loader.py:                line = line.strip()
./flask_model_server/utils/config_loader.py:                if line and not line.startswith("#") and "=" in line:
./flask_model_server/utils/config_loader.py:                    key, value = line.split("=", 1)
./flask_model_server/utils/config_loader.py:                    key = key.strip()
./flask_model_server/utils/config_loader.py:                    value = value.strip()
./flask_model_server/utils/config_loader.py:                    try:
./flask_model_server/utils/config_loader.py:                        params[key] = int(value)
./flask_model_server/utils/config_loader.py:                    except ValueError:
./flask_model_server/utils/config_loader.py:                        try:
./flask_model_server/utils/config_loader.py:                            params[key] = float(value)
./flask_model_server/utils/config_loader.py:                        except ValueError:
./flask_model_server/utils/config_loader.py:                            params[key] = value
./flask_model_server/utils/config_loader.py:    else:
./flask_model_server/utils/config_loader.py:        print(f"Arquivo {file_path} não encontrado. Usando parâmetros padrão.")
./flask_model_server/utils/config_loader.py:    return params
./flask_model_server/utils/data_utils.py:import numpy as np
./flask_model_server/utils/data_utils.py:import pandas as pd
./flask_model_server/utils/data_utils.py:import yfinance as yf
./flask_model_server/utils/data_utils.py:from datetime import datetime, timedelta
./flask_model_server/utils/data_utils.py:from sklearn.preprocessing import MinMaxScaler
./flask_model_server/utils/data_utils.py:from config import LAST_UPDATE_FILE
./flask_model_server/utils/data_utils.py:
./flask_model_server/utils/data_utils.py:def download_data_from_yfinance(start_date, ticker):
./flask_model_server/utils/data_utils.py:    end_date = datetime.today().date()
./flask_model_server/utils/data_utils.py:    df = yf.download(ticker, start=start_date, end=end_date, progress=False)
./flask_model_server/utils/data_utils.py:    return df if not df.empty else None
./flask_model_server/utils/data_utils.py:
./flask_model_server/utils/data_utils.py:def preprocess_data(df, sequence_length, device):
./flask_model_server/utils/data_utils.py:    df = df[["Close"]].astype(float)
./flask_model_server/utils/data_utils.py:    scaler = MinMaxScaler(feature_range=(0, 1))
./flask_model_server/utils/data_utils.py:    df_scaled = scaler.fit_transform(df)
./flask_model_server/utils/data_utils.py:
./flask_model_server/utils/data_utils.py:    X, y = [], []
./flask_model_server/utils/data_utils.py:    for i in range(sequence_length, len(df_scaled)):
./flask_model_server/utils/data_utils.py:        X.append(df_scaled[i - sequence_length:i])
./flask_model_server/utils/data_utils.py:        y.append(df_scaled[i])
./flask_model_server/utils/data_utils.py:    X = np.array(X, dtype=np.float32)
./flask_model_server/utils/data_utils.py:    y = np.array(y, dtype=np.float32)
./flask_model_server/utils/data_utils.py:    return X, y, scaler
./flask_model_server/utils/file_utils.py:# Funções utilitárias para manipulação de arquivos.
./flask_model_server/utils/file_utils.py:# (Implementações podem ser adicionadas conforme necessário.)
./flask_model_server/Dockerfile:# Imagem base com CUDA e cuDNN (Ubuntu 20.04)
./flask_model_server/Dockerfile:FROM nvidia/cuda:11.6.1-cudnn8-runtime-ubuntu20.04
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Instala dependências do sistema e Python
./flask_model_server/Dockerfile:RUN apt-get update && apt-get install -y \
./flask_model_server/Dockerfile:    python3 \
./flask_model_server/Dockerfile:    python3-pip \
./flask_model_server/Dockerfile:    && rm -rf /var/lib/apt/lists/*
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Define o diretório de trabalho dentro do container
./flask_model_server/Dockerfile:WORKDIR /app
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Copia o arquivo de dependências e instala as bibliotecas necessárias
./flask_model_server/Dockerfile:COPY requirements.txt .
./flask_model_server/Dockerfile:RUN pip3 install --upgrade pip && pip3 install -r requirements.txt
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Copia todo o código fonte para dentro do container
./flask_model_server/Dockerfile:COPY . .
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Define as variáveis de ambiente para o Flask
./flask_model_server/Dockerfile:ENV FLASK_APP=app.py
./flask_model_server/Dockerfile:ENV FLASK_RUN_HOST=0.0.0.0
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Expõe a porta 5000 (onde a aplicação Flask irá rodar)
./flask_model_server/Dockerfile:EXPOSE 5000
./flask_model_server/Dockerfile:
./flask_model_server/Dockerfile:# Comando para iniciar a aplicação Flask
./flask_model_server/Dockerfile:CMD ["flask", "run"]
./.env:COMPOSE_PROJECT_NAME=tc4
./mlflow_server/requirements.txt:mlflow==2.17.1
./mlflow_server/local_run.sh:#!/usr/bin/env bash
./mlflow_server/local_run.sh:source .venv/bin/activate
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:SCRIPT_PATH="$(readlink -f "$0")"
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:THREE_LEVELS_UP="$(dirname "$(dirname "$(dirname "$SCRIPT_PATH")")")"
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:# Caminho para o arquivo SQLite
./mlflow_server/local_run.sh:DB_PATH="$THREE_LEVELS_UP/local_storage/mlflow_logs/mlflow.db"
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:# Caminho para os artifacts do MLflow
./mlflow_server/local_run.sh:ARTIFACT_PATH="$THREE_LEVELS_UP/local_storage/training_artifacts"
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:echo "DB_PATH: ${DB_PATH}"
./mlflow_server/local_run.sh:echo "ARTIFACT_PATH: ${ARTIFACT_PATH}"
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:# Inicia o servidor MLflow utilizando os caminhos construídos.
./mlflow_server/local_run.sh:mlflow server \
./mlflow_server/local_run.sh:  --backend-store-uri sqlite:///"${DB_PATH}" \
./mlflow_server/local_run.sh:  --default-artifact-root file:///"${ARTIFACT_PATH}" \
./mlflow_server/local_run.sh:  --host 0.0.0.0 \
./mlflow_server/local_run.sh:  --port 5001
./mlflow_server/local_run.sh:
./mlflow_server/local_run.sh:deactivate
./mlflow_server/local_setup.sh:#!/usr/bin/env bash
./mlflow_server/local_setup.sh:python3 -m venv .venv
./mlflow_server/local_setup.sh:source .venv/bin/activate
./mlflow_server/local_setup.sh:pip3 install -r requirements.txt
./mlflow_server/local_setup.sh:deactivate
./mlflow_server/Dockerfile:# Imagem base com CUDA e cuDNN (Ubuntu 20.04)
./mlflow_server/Dockerfile:FROM python:3.10-slim
./mlflow_server/Dockerfile:
./mlflow_server/Dockerfile:# Instala dependências do sistema e Python
./mlflow_server/Dockerfile:RUN apt-get update && apt-get install -y \
./mlflow_server/Dockerfile:    python3 \
./mlflow_server/Dockerfile:    python3-pip \
./mlflow_server/Dockerfile:    && rm -rf /var/lib/apt/lists/*
./mlflow_server/Dockerfile:
./mlflow_server/Dockerfile:# Copia o arquivo de dependências e instala as bibliotecas necessárias
./mlflow_server/Dockerfile:COPY requirements.txt .
./mlflow_server/Dockerfile:RUN pip3 install --upgrade pip && pip3 install -r requirements.txt
./mlflow_server/Dockerfile:
./mlflow_server/Dockerfile:# Copia todo o código fonte para dentro do container
./mlflow_server/Dockerfile:COPY . .
./mlflow_server/Dockerfile:
./mlflow_server/Dockerfile:EXPOSE 5001
./mlflow_server/Dockerfile:
./mlflow_server/Dockerfile:# Comando para iniciar a aplicação Flask
./mlflow_server/Dockerfile:CMD ["mlflow", "server", "--backend-store-uri", "sqlite:////storage/mlflow_logs/mlflow.db", "--default-artifact-root", "file:////storage/training_artifacts", "--host", "0.0.0.0", "--port", "5001"]
